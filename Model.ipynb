{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "trainset = datasets.MNIST('TrainSet', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('ValSet', download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, Y = dataiter.next()\n",
    "images = images.numpy()\n",
    "X = np.resize(images,(64,784))\n",
    "Y = Y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newY = np.zeros(shape=(64,10))\n",
    "for i in range(Y.shape[0]):\n",
    "    newY[i,Y[i]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSigmoid(T, x):\n",
    "    numerator = np.exp(np.matmul(x,T))\n",
    "    denomenator = numerator + 1 \n",
    "    sig = np.divide(numerator,denomenator)\n",
    "    return sig\n",
    "\n",
    "def getLoss(T, Y, x):\n",
    "    m = np.prod(Y.shape)\n",
    "    activation = getSigmoid(T,x)\n",
    "    loss= np.square(np.subtract(activation, Y))\n",
    "    print(loss)\n",
    "    loss = np.sum(loss)\n",
    "    print(loss)\n",
    "    loss = np.multiply(loss, 1/(2 * m))\n",
    "    return loss\n",
    "\n",
    "def getGradient(weights, Y, X):\n",
    "    activation = getSigmoid(weights,X)\n",
    "    z = np.square(np.subtract(activation, Y))\n",
    "    gradient = np.matmul(X.transpose(), z)\n",
    "    print(z)\n",
    "    return gradient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.21099238e-277 7.06104554e-275 7.48752687e-274 1.36781044e-282\n",
      "  1.06389821e-280 2.49830523e-281 4.90819744e-282 1.00000000e+000\n",
      "  7.10328466e-290 2.55238176e-272]\n",
      " [1.41424699e-266 1.22266271e-260 9.29542851e-252 2.42317849e-262\n",
      "  3.80681381e-261 1.97602091e-263 9.77508945e-266 1.00000000e+000\n",
      "  4.36755328e-277 2.87926053e-251]\n",
      " [3.89976972e-255 1.95973685e-258 1.00000000e+000 4.54295292e-261\n",
      "  2.91198231e-252 1.71802975e-258 7.28204552e-249 1.00836230e-259\n",
      "  3.65464206e-265 1.15695503e-249]\n",
      " [2.14505930e-265 7.98272757e-275 4.49549317e-259 1.00000000e+000\n",
      "  1.14563672e-265 1.55548638e-263 8.16238685e-270 1.31282297e-268\n",
      "  2.83560187e-271 4.80009352e-255]\n",
      " [6.75036304e-263 6.65315849e-268 1.36023717e-255 1.29328314e-267\n",
      "  1.77265422e-266 1.00000000e+000 1.81269116e-258 1.88185225e-268\n",
      "  1.76350398e-274 6.37840045e-260]\n",
      " [1.06949382e-243 5.15049249e-255 1.00000000e+000 5.18565111e-248\n",
      "  9.50927849e-251 4.11191022e-255 2.69817339e-249 1.64021773e-252\n",
      "  1.13872671e-257 7.04552374e-235]\n",
      " [1.52454296e-250 1.11984121e-242 5.09508008e-245 1.00000000e+000\n",
      "  1.69370676e-244 1.01082831e-253 9.56559748e-246 7.34626238e-251\n",
      "  1.37195460e-257 6.10310334e-241]\n",
      " [5.78167805e-227 2.14915233e-225 3.61796115e-216 1.00000000e+000\n",
      "  1.95983982e-222 1.45991607e-224 2.92022657e-220 2.26709270e-229\n",
      "  9.59421538e-231 3.48516240e-216]\n",
      " [6.13333924e-221 1.34463327e-215 8.83210281e-218 3.93216934e-221\n",
      "  5.90095665e-217 1.39644477e-231 2.14394019e-220 1.25552745e-223\n",
      "  1.00000000e+000 1.91401202e-215]\n",
      " [1.00000000e+000 1.60845977e-233 4.27432859e-227 6.39896517e-235\n",
      "  2.76129733e-236 1.07727814e-231 4.92449791e-234 7.25546328e-243\n",
      "  2.77063594e-241 4.25951840e-225]\n",
      " [8.50768320e-273 1.00000000e+000 1.33497462e-269 9.32982078e-278\n",
      "  1.72453580e-278 2.41842173e-278 1.50770268e-273 1.31861722e-280\n",
      "  3.14115078e-285 1.88555633e-270]\n",
      " [1.12701698e-294 1.00000000e+000 6.06758021e-287 2.45996994e-294\n",
      "  2.09461235e-298 1.31447832e-291 4.06737671e-289 4.40265765e-297\n",
      "  4.71098884e-305 3.23340285e-290]\n",
      " [2.66840679e-264 3.04075155e-267 1.00000000e+000 9.91444848e-265\n",
      "  1.46517991e-266 5.81546959e-264 6.03658195e-265 2.37465265e-270\n",
      "  1.35015539e-276 3.22686074e-260]\n",
      " [7.02133141e-225 1.24012434e-228 3.87872943e-221 3.64659828e-228\n",
      "  2.72471404e-221 1.78990178e-233 1.83773724e-222 2.71930283e-230\n",
      "  1.00000000e+000 7.67384465e-221]\n",
      " [1.00000000e+000 6.50052832e-210 3.28561875e-210 3.06171800e-213\n",
      "  9.13307084e-212 5.62623995e-212 3.96529854e-211 1.48072815e-225\n",
      "  3.16800300e-223 6.57040414e-204]\n",
      " [3.11662039e-264 1.42209609e-259 6.18575751e-260 1.72664615e-270\n",
      "  8.46521395e-265 2.02922282e-273 3.31807116e-262 5.91307373e-268\n",
      "  1.00000000e+000 1.54640188e-258]\n",
      " [2.82046302e-232 1.69877957e-245 1.01361532e-231 1.10508227e-240\n",
      "  7.36787171e-238 1.36503237e-243 1.00000000e+000 3.03861942e-251\n",
      "  1.98332205e-255 6.75266541e-234]\n",
      " [3.88454564e-267 1.32392982e-260 4.45382525e-261 4.81496037e-269\n",
      "  1.00000000e+000 2.14145993e-274 4.71297516e-264 1.28630115e-269\n",
      "  5.97417317e-283 2.97835782e-261]\n",
      " [8.13783038e-244 9.48375487e-247 9.82368126e-239 1.00000000e+000\n",
      "  3.62560650e-245 1.07842530e-251 1.84457032e-248 5.52797168e-247\n",
      "  1.66370764e-254 4.67940767e-234]\n",
      " [3.63972258e-235 2.41027228e-238 1.07379927e-230 1.00000000e+000\n",
      "  1.18256332e-236 8.58618427e-236 4.26238477e-231 5.53544757e-233\n",
      "  4.81630288e-242 1.09075033e-226]\n",
      " [1.00000000e+000 1.12671508e-274 6.45230496e-263 5.90465507e-270\n",
      "  5.56464022e-272 9.17562391e-274 7.58579356e-266 1.24420850e-270\n",
      "  7.74001599e-278 1.55591904e-258]\n",
      " [1.39307555e-294 1.00000000e+000 1.94174621e-278 3.86495770e-297\n",
      "  3.12413217e-291 4.17812663e-296 1.05514382e-289 7.85658436e-294\n",
      "  2.43817671e-303 3.84257135e-286]\n",
      " [2.14268964e-241 5.30291086e-238 2.93655301e-231 1.05776710e-236\n",
      "  2.69520974e-242 4.83283811e-241 1.00000000e+000 8.76455849e-239\n",
      "  1.62390375e-250 2.53645027e-234]\n",
      " [2.38414198e-207 9.88741378e-206 1.00000000e+000 8.43182839e-205\n",
      "  5.18679076e-196 1.20183053e-202 1.60678254e-194 2.14218515e-202\n",
      "  6.89834704e-205 8.81317726e-198]\n",
      " [7.92659632e-257 2.97296444e-258 1.00000000e+000 2.95447336e-253\n",
      "  2.76429679e-260 6.05813269e-261 3.67540008e-251 2.94063909e-259\n",
      "  4.92844969e-264 4.72047155e-250]\n",
      " [2.03946280e-248 1.31706999e-249 9.36436559e-249 9.89312498e-259\n",
      "  5.97128668e-251 3.50147672e-260 1.70263258e-258 1.00000000e+000\n",
      "  4.40641459e-263 7.24567014e-248]\n",
      " [9.21065137e-243 7.42066520e-256 6.15380332e-240 4.66674224e-254\n",
      "  1.64632643e-246 1.00000000e+000 1.63214051e-243 1.02370760e-252\n",
      "  1.64323585e-259 6.67475676e-233]\n",
      " [2.25239958e-302 1.00000000e+000 1.91602797e-293 3.10374095e-303\n",
      "  4.90193973e-305 6.36140651e-300 3.28594372e-296 4.67027295e-305\n",
      "  2.27202097e-310 4.26066452e-296]\n",
      " [1.13091554e-260 7.79416691e-265 1.36636039e-269 1.79780285e-269\n",
      "  1.00000000e+000 3.06449920e-268 4.85096407e-267 1.81724952e-275\n",
      "  9.75287442e-283 8.73892318e-262]\n",
      " [3.84622071e-283 1.00000000e+000 1.25693582e-268 5.16262416e-287\n",
      "  2.34547493e-280 1.44541084e-281 9.53122691e-281 1.66771741e-282\n",
      "  5.40979009e-290 1.50291911e-275]\n",
      " [1.32892695e-278 1.02719000e-279 1.36993006e-266 8.31608434e-278\n",
      "  4.92231502e-286 4.85748556e-284 1.00000000e+000 4.07244068e-279\n",
      "  3.48574154e-291 2.13785724e-268]\n",
      " [5.50276095e-276 1.02087964e-276 3.07566762e-270 9.21709820e-276\n",
      "  4.30360266e-274 3.15181810e-278 5.63679248e-281 1.00000000e+000\n",
      "  1.78180360e-290 1.12718605e-267]\n",
      " [1.43141079e-231 7.85271963e-244 8.20247075e-238 7.30432504e-243\n",
      "  1.05388962e-243 5.89810470e-240 1.00000000e+000 6.95689272e-253\n",
      "  2.79487810e-257 2.36365770e-236]\n",
      " [9.86849766e-307 1.00000000e+000 1.81482264e-295 1.80340122e-305\n",
      "  1.00930521e-311 2.46260225e-304 1.64895465e-301 4.07409699e-311\n",
      "  2.55431939e-321 1.05732794e-300]\n",
      " [9.29049631e-240 5.90868492e-236 1.00000000e+000 2.28852040e-240\n",
      "  4.89221033e-240 3.76549908e-248 3.95335388e-236 9.47257814e-244\n",
      "  1.78133177e-249 1.59166652e-226]\n",
      " [5.59081056e-256 1.00044146e-250 5.16666088e-247 1.00000000e+000\n",
      "  1.40272370e-259 2.09881999e-254 1.74842057e-249 6.84488461e-259\n",
      "  5.33644083e-265 1.81471743e-243]\n",
      " [1.34607460e-228 1.18092315e-228 6.82817023e-230 1.00000000e+000\n",
      "  3.06551635e-237 4.86645618e-241 1.28185379e-226 7.20215324e-235\n",
      "  3.26892187e-238 4.87834860e-222]\n",
      " [9.92645207e-242 3.72268950e-236 1.00000000e+000 6.69021667e-233\n",
      "  4.46054482e-237 1.12950340e-241 1.05730500e-231 2.55480113e-244\n",
      "  1.11302285e-246 1.96152016e-233]\n",
      " [2.35623492e-246 5.96225244e-242 7.07960210e-247 5.96265201e-247\n",
      "  1.84321313e-245 2.90941431e-245 2.81036375e-242 1.73386224e-256\n",
      "  2.30842511e-253 1.00000000e+000]\n",
      " [2.07661375e-268 1.02904145e-265 5.43816017e-263 2.76509166e-275\n",
      "  1.00000000e+000 2.95991172e-270 3.32593871e-274 6.00997188e-278\n",
      "  1.64383622e-279 9.83471193e-260]\n",
      " [3.10358447e-266 2.18173564e-267 1.85393259e-262 1.65808114e-266\n",
      "  2.28762693e-271 3.98515044e-271 1.00000000e+000 7.44773352e-277\n",
      "  6.29436983e-282 9.08825979e-260]\n",
      " [9.74735921e-280 4.04993572e-278 3.44475609e-274 1.85086522e-278\n",
      "  1.84218588e-281 1.53121293e-282 2.48891637e-274 1.00000000e+000\n",
      "  1.72502988e-295 1.18504853e-273]\n",
      " [1.47500888e-270 5.12738028e-272 9.08591679e-273 1.62979092e-277\n",
      "  1.00000000e+000 2.06230554e-279 5.69363538e-275 3.98055657e-277\n",
      "  1.27704449e-288 6.52519496e-263]\n",
      " [2.92471604e-272 3.82880504e-269 1.53829814e-267 1.00000000e+000\n",
      "  1.87514156e-273 2.54688364e-281 7.00181555e-274 1.11006214e-276\n",
      "  4.83928683e-282 7.25890225e-265]\n",
      " [2.56778048e-254 3.70103857e-250 1.38234348e-245 1.00000000e+000\n",
      "  1.15038671e-252 1.88217291e-251 4.33349011e-248 1.57979439e-257\n",
      "  3.93527695e-257 2.48962434e-246]\n",
      " [1.03543787e-249 4.29579419e-255 1.65688031e-253 9.71392424e-264\n",
      "  1.00000000e+000 9.62868462e-260 1.70638208e-259 1.78417437e-263\n",
      "  2.83983940e-274 8.78303298e-251]\n",
      " [1.00000000e+000 7.59725511e-252 2.48900648e-241 1.28017269e-241\n",
      "  2.83547685e-253 1.63794799e-251 3.87336210e-244 8.12157681e-249\n",
      "  3.75580809e-260 1.60188284e-238]\n",
      " [9.45795222e-252 8.26891917e-246 1.52773815e-249 4.19291229e-254\n",
      "  1.57379364e-251 8.71531343e-261 4.72197694e-247 3.17950245e-255\n",
      "  1.40161035e-263 1.00000000e+000]\n",
      " [3.32200672e-242 1.00232405e-238 1.68021793e-236 9.79600382e-230\n",
      "  8.33925767e-247 6.39436232e-246 1.00000000e+000 1.30296012e-243\n",
      "  1.74074479e-256 9.59953654e-230]\n",
      " [4.37515537e-300 1.00000000e+000 1.01897540e-282 5.67691050e-301\n",
      "  1.59053127e-300 5.42290225e-299 2.54487457e-297 1.64678459e-299\n",
      "  3.03061769e-311 5.22608490e-292]\n",
      " [2.92518462e-287 2.87456217e-286 6.44200420e-280 2.65172195e-290\n",
      "  1.00000000e+000 1.06657460e-293 2.28474466e-282 1.18924048e-288\n",
      "  6.81731139e-301 3.05612610e-280]\n",
      " [5.18566962e-226 2.84721466e-232 1.86440645e-219 3.85950093e-225\n",
      "  3.27570307e-224 5.04898821e-230 1.00000000e+000 9.03403876e-234\n",
      "  2.88638444e-240 4.28361223e-219]\n",
      " [7.24340184e-301 1.00000000e+000 1.67063226e-295 1.40193736e-303\n",
      "  3.03602369e-306 1.77862884e-301 6.49394581e-298 1.16658205e-305\n",
      "  8.21117959e-311 1.20126650e-296]\n",
      " [1.00000000e+000 6.88414344e-182 3.83743476e-178 2.37498975e-172\n",
      "  5.46960752e-180 6.90687467e-178 4.30413683e-176 4.15728817e-181\n",
      "  1.84011227e-189 1.32560916e-173]\n",
      " [2.25773845e-290 1.00000000e+000 5.67025984e-284 2.95764016e-291\n",
      "  1.11386115e-293 7.55660925e-289 9.40417777e-287 3.98246539e-294\n",
      "  1.54254817e-299 1.74969398e-286]\n",
      " [6.93392566e-261 6.55026080e-258 4.65998454e-256 3.79327789e-263\n",
      "  4.84777030e-266 2.22932343e-270 1.27258825e-264 7.70544877e-266\n",
      "  1.00000000e+000 4.69653529e-260]\n",
      " [1.00000000e+000 1.16855062e-235 3.73933294e-234 2.32534498e-227\n",
      "  5.32551890e-235 1.02446902e-227 3.90382427e-231 7.65132578e-233\n",
      "  3.29168964e-246 8.25377936e-227]\n",
      " [1.00000000e+000 1.49932629e-232 3.97410069e-224 3.27926782e-225\n",
      "  5.51976412e-230 3.13873420e-238 2.83403627e-229 8.81362121e-227\n",
      "  4.83167293e-242 4.00697963e-223]\n",
      " [6.81964981e-243 4.13082973e-250 1.78233258e-242 1.00000000e+000\n",
      "  2.27520565e-249 1.00709733e-250 9.39224228e-246 3.46012349e-258\n",
      "  1.13764433e-258 3.20626177e-241]\n",
      " [2.52322516e-287 9.47302281e-288 1.66154739e-278 4.64367504e-287\n",
      "  4.81869319e-293 1.00000000e+000 2.65736068e-290 1.82426399e-288\n",
      "  4.59154308e-300 9.43326228e-285]\n",
      " [2.85673767e-232 1.24852201e-235 2.35450627e-231 7.62152306e-233\n",
      "  2.17508901e-239 8.92391445e-237 1.00000000e+000 3.11218912e-244\n",
      "  8.82530891e-245 7.93982166e-229]\n",
      " [7.77844531e-266 4.05030867e-264 1.88391259e-262 2.66959880e-270\n",
      "  4.44251872e-272 6.46894805e-271 2.58159503e-267 1.00000000e+000\n",
      "  6.22863286e-278 5.23543423e-260]\n",
      " [3.07999077e-294 1.00000000e+000 5.01088139e-290 5.20389946e-297\n",
      "  8.53057203e-301 2.44635130e-295 1.68198080e-295 5.67342732e-298\n",
      "  4.38470948e-305 1.26111738e-291]\n",
      " [1.00212254e-237 1.01216001e-242 2.32784532e-232 3.50410625e-246\n",
      "  3.54875264e-238 1.94782681e-247 1.00000000e+000 5.02025000e-250\n",
      "  1.17144495e-255 2.15262442e-241]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -7., -10.,  -7., ...,  -6.,  -4.,  -2.],\n",
       "       [ -7., -10.,  -7., ...,  -6.,  -4.,  -2.],\n",
       "       [ -7., -10.,  -7., ...,  -6.,  -4.,  -2.],\n",
       "       ...,\n",
       "       [ -7., -10.,  -7., ...,  -6.,  -4.,  -2.],\n",
       "       [ -7., -10.,  -7., ...,  -6.,  -4.,  -2.],\n",
       "       [ -7., -10.,  -7., ...,  -6.,  -4.,  -2.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.random.rand(784,10)\n",
    "getGradient(theta, newY, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to train the logistic regression model\n",
    "def train_logistic_regression(X, y, num_iterations=100, learning_rate=0.01):\n",
    "    # Initialize the weights with random values\n",
    "    weights = np.random.randn(785)\n",
    "    X = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Add a bias term to the input\n",
    "        \n",
    "        # Compute the dot product of the input and the weights\n",
    "        z = np.dot(X, weights)\n",
    "        \n",
    "        # Apply the sigmoid function to the dot product to get the predicted probability\n",
    "        y_pred = 1 / (1 + np.exp(-z))\n",
    "        \n",
    "        # Compute the error\n",
    "        error = y_pred - y\n",
    "        \n",
    "        # Update the weights using gradient descent\n",
    "        weights -= learning_rate * np.dot(X.T, error)\n",
    "        \n",
    "    return weights\n",
    "\n",
    "# Function to make predictions with the logistic regression model\n",
    "def predict(X, weights):\n",
    "    # Add a bias term to the input\n",
    "    X = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
    "    \n",
    "    # Compute the dot product of the input and the weights\n",
    "    z = np.dot(X, weights)\n",
    "    \n",
    "    # Apply the sigmoid function to the dot product to get the predicted probability\n",
    "    y_pred = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    # Return the predicted digits by taking the argmax of the predicted probabilities\n",
    "    return y_pred\n",
    "\n",
    "# Load the training data\n",
    "X_train = X\n",
    "y_train = Y\n",
    "\n",
    "# Train the model\n",
    "weights = train_logistic_regression(X_train, y_train)\n",
    "\n",
    "# Load the test data\n",
    "X_test = ...\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = predict(X, weights)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def logistic_regression(x, weights):\n",
    "    \n",
    "    # Compute the dot product of the input and the weights\n",
    "    z = np.dot(x, weights)\n",
    "    \n",
    "    # Apply the sigmoid function to the dot product to get the predicted probability\n",
    "    y_pred = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    # Return the predicted digit by taking the argmax of the predicted probabilities\n",
    "    return np.argmax(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41a8bb042236853c4d003d0bbfa761c6f3a71c5f238884c2a97247d6653e3ced"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
